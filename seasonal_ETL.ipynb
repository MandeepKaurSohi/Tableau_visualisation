{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "246c82ec-be64-4382-a26f-8aa8c151bab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dependencies\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cdd286ef-7642-48a9-a812-5ed4e670b8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jan_2024.csv', 'nov_2024.csv', '.DS_Store', 'oct_2024.csv', 'July_2024.csv', 'sep_2024.csv']\n"
     ]
    }
   ],
   "source": [
    "# Folder path\n",
    "folder_path = \"/Users/harwinder/Desktop/Tableau_Project/Resources/\"\n",
    "print(os.listdir(folder_path))  # List files in the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f42e140-41ef-49d6-bb48-8308c95cefb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "file_names = ['Jan_2024.csv', 'July_2024.csv']\n",
    "file_paths = [os.path.join(folder_path, file_name) for file_name in file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cab754e2-f558-4f3f-aa1b-25400862bff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: /Users/harwinder/Desktop/Tableau_Project/Resources/Jan_2024.csv\n",
      "Loading file: /Users/harwinder/Desktop/Tableau_Project/Resources/July_2024.csv\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store DataFrames\n",
    "data_frames = []\n",
    "\n",
    "# Loop through each file and load only 5000 rows\n",
    "for file_path in file_paths:\n",
    "    print(f\"Loading file: {file_path}\")\n",
    "    data = pd.read_csv(file_path, nrows=5000)  # Limit to 5000 rows\n",
    "    data_frames.append(data)  # Append the DataFrame to the list\n",
    "\n",
    "# Merge all DataFrames into one\n",
    "merged_dataset = pd.concat(data_frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0deb024-1cd8-44de-bb86-1096e246f8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in merged data: 10000\n",
      "            ride_id  rideable_type               started_at  \\\n",
      "0  5078F3D302000BD2  electric_bike  2024-01-22 18:43:19.012   \n",
      "1  814337105D37302A  electric_bike  2024-01-11 19:19:18.721   \n",
      "2  A33A920E2B10710C  electric_bike  2024-01-30 19:17:41.693   \n",
      "3  A3A5FC0DD7D34D74  electric_bike  2024-01-27 11:27:01.759   \n",
      "4  6F96728ECEFBDAA4  electric_bike  2024-01-16 15:15:41.000   \n",
      "\n",
      "                  ended_at                  start_station_name  \\\n",
      "0  2024-01-22 18:48:10.708  Frederick Douglass Blvd & W 145 St   \n",
      "1  2024-01-11 19:47:36.007                     W 54 St & 6 Ave   \n",
      "2  2024-01-30 19:32:49.857                     E 11 St & Ave B   \n",
      "3  2024-01-27 11:38:01.213                     W 54 St & 6 Ave   \n",
      "4  2024-01-16 15:29:26.156               Madison Ave & E 99 St   \n",
      "\n",
      "  start_station_id            end_station_name end_station_id  start_lat  \\\n",
      "0          7954.12  St Nicholas Ave & W 126 St        7756.10  40.823072   \n",
      "1          6771.13             E 74 St & 1 Ave        6953.08  40.761822   \n",
      "2          5659.11     W 10 St & Washington St        5847.06  40.727592   \n",
      "3          6771.13             E 74 St & 1 Ave        6953.08  40.761779   \n",
      "4          7443.01             E 74 St & 1 Ave        6953.08  40.789808   \n",
      "\n",
      "   start_lng    end_lat    end_lng member_casual  Unnamed: 0  \n",
      "0 -73.941738  40.811432 -73.951878        member         NaN  \n",
      "1 -73.977036  40.768974 -73.954823        member         NaN  \n",
      "2 -73.979751  40.733424 -74.008515        casual         NaN  \n",
      "3 -73.977144  40.768974 -73.954823        member         NaN  \n",
      "4 -73.952214  40.768974 -73.954823        member         NaN  \n",
      "Merged file saved to: /Users/harwinder/Desktop/Tableau_Project/Resources/seasonal_citibike_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Check the merged data\n",
    "print(f\"Number of rows in merged data: {len(merged_dataset)}\")\n",
    "print(merged_dataset.head())\n",
    "\n",
    "# Save the merged file\n",
    "output_file = os.path.join(folder_path, \"seasonal_citibike_data.csv\")\n",
    "merged_dataset.to_csv(output_file, index=False)\n",
    "print(f\"Merged file saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2a1c1b4-80fb-4dd8-a685-5daf66cc92dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   ride_id             10000 non-null  object \n",
      " 1   rideable_type       10000 non-null  object \n",
      " 2   started_at          10000 non-null  object \n",
      " 3   ended_at            10000 non-null  object \n",
      " 4   start_station_name  9993 non-null   object \n",
      " 5   start_station_id    9993 non-null   object \n",
      " 6   end_station_name    9858 non-null   object \n",
      " 7   end_station_id      9858 non-null   object \n",
      " 8   start_lat           10000 non-null  float64\n",
      " 9   start_lng           10000 non-null  float64\n",
      " 10  end_lat             9986 non-null   float64\n",
      " 11  end_lng             9986 non-null   float64\n",
      " 12  member_casual       10000 non-null  object \n",
      " 13  Unnamed: 0          5000 non-null   float64\n",
      "dtypes: float64(5), object(9)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Reload the merged file for further processing\n",
    "merged_dataset = pd.read_csv(output_file)\n",
    "merged_dataset.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ed6fcda-6c28-419b-a473-29ec7b92cfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before handling:\n",
      "ride_id                  0\n",
      "rideable_type            0\n",
      "started_at               0\n",
      "ended_at                 0\n",
      "start_station_name       7\n",
      "start_station_id         7\n",
      "end_station_name       142\n",
      "end_station_id         142\n",
      "start_lat                0\n",
      "start_lng                0\n",
      "end_lat                 14\n",
      "end_lng                 14\n",
      "member_casual            0\n",
      "Unnamed: 0            5000\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values before handling:\")\n",
    "print(merged_dataset.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01280b9a-46aa-4b2e-b213-6fdccc22ab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "merged_dataset['start_station_name'] = merged_dataset['start_station_name'].fillna('Unknown')\n",
    "merged_dataset['end_station_name'] = merged_dataset['end_station_name'].fillna('Unknown')\n",
    "merged_dataset['start_station_id'] = merged_dataset['start_station_id'].fillna(-1)\n",
    "merged_dataset['end_station_id'] = merged_dataset['end_station_id'].fillna(-1)\n",
    "merged_dataset = merged_dataset.dropna(subset=['end_lat', 'end_lng'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1644d41-b1a8-4eca-8537-ee3e369f722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "merged_dataset = merged_dataset.drop(columns=['Unnamed: 0'], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78d819f1-0dca-4578-aea3-2bb64f0e9d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to datetime\n",
    "merged_dataset['started_at'] = pd.to_datetime(merged_dataset['started_at'], errors='coerce')\n",
    "merged_dataset['ended_at'] = pd.to_datetime(merged_dataset['ended_at'], errors='coerce')\n",
    "\n",
    "# Ensure IDs are numeric\n",
    "merged_dataset['start_station_id'] = pd.to_numeric(merged_dataset['start_station_id'], errors='coerce').fillna(-1).astype('int64')\n",
    "merged_dataset['end_station_id'] = pd.to_numeric(merged_dataset['end_station_id'], errors='coerce').fillna(-1).astype('int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fe195d81-1f2a-47ec-8208-d18d37d3bdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new calculated columns\n",
    "merged_dataset['trip_duration_minutes'] = (merged_dataset['ended_at'] - merged_dataset['started_at']).dt.total_seconds() / 60\n",
    "merged_dataset['day_of_week'] = merged_dataset['started_at'].dt.day_name()\n",
    "merged_dataset['hour_of_day'] = merged_dataset['started_at'].dt.hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca71d8c9-9424-4755-a2e2-c58a8f5f261e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter invalid data\n",
    "merged_dataset = merged_dataset[merged_dataset['trip_duration_minutes'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7733c05a-c9db-4a0e-8dd0-23e6650e6814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize text columns\n",
    "merged_dataset['start_station_name'] = merged_dataset['start_station_name'].str.strip()\n",
    "merged_dataset['end_station_name'] = merged_dataset['end_station_name'].str.strip()\n",
    "merged_dataset['rideable_type'] = merged_dataset['rideable_type'].str.lower()\n",
    "merged_dataset['member_casual'] = merged_dataset['member_casual'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e5d484f-5862-4792-9c2c-026a21d15588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "merged_dataset = merged_dataset.rename(columns={\n",
    "    'ride_id': 'Ride Id', 'rideable_type': 'Rideable Type', 'started_at': 'Started At',\n",
    "    'ended_at': 'Ended At', 'start_station_name': 'Start Station Name',\n",
    "    'start_station_id': 'Start Station Id', 'end_station_name': 'End Station Name',\n",
    "    'end_station_id': 'End Station Id', 'start_lat': 'Start Lat', 'start_lng': 'Start Lng',\n",
    "    'end_lat': 'End Lat', 'end_lng': 'End Lng', 'member_casual': 'Member Casual'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9af0c849-a288-4b67-b053-e490fdace69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types and ensure correctness\n",
    "expected_dtypes = {\n",
    "    'Ride Id': 'str',\n",
    "    'Rideable Type': 'category',\n",
    "    'Started At': 'datetime64[ns]',\n",
    "    'Ended At': 'datetime64[ns]',\n",
    "    'Start Station Name': 'str',\n",
    "    'Start Station Id': 'int64',\n",
    "    'End Station Name': 'str',\n",
    "    'End Station Id': 'int64',\n",
    "    'Start Lat': 'float64',\n",
    "    'Start Lng': 'float64',\n",
    "    'End Lat': 'float64',\n",
    "    'End Lng': 'float64',\n",
    "    'Member Casual': 'category',\n",
    "    'trip_duration_minutes': 'float64',\n",
    "    'day_of_week': 'str',\n",
    "    'hour_of_day': 'int64'\n",
    "}\n",
    "\n",
    "for column, dtype in expected_dtypes.items():\n",
    "    if column in merged_dataset.columns and merged_dataset[column].dtype != dtype:\n",
    "        try:\n",
    "            merged_dataset[column] = merged_dataset[column].astype(dtype)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not convert {column} to {dtype}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e4dd260-e2cf-423e-ac37-8258296ad098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Data Types:\n",
      "\n",
      "Ride Id                          object\n",
      "Rideable Type                  category\n",
      "Started At               datetime64[ns]\n",
      "Ended At                 datetime64[ns]\n",
      "Start Station Name               object\n",
      "Start Station Id                  int64\n",
      "End Station Name                 object\n",
      "End Station Id                    int64\n",
      "Start Lat                       float64\n",
      "Start Lng                       float64\n",
      "End Lat                         float64\n",
      "End Lng                         float64\n",
      "Member Casual                  category\n",
      "trip_duration_minutes           float64\n",
      "day_of_week                      object\n",
      "hour_of_day                       int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Verify final data types\n",
    "print(\"\\nFinal Data Types:\\n\")\n",
    "print(merged_dataset.dtypes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e28b3cc2-0696-47bb-aded-752ba3a3d471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to: /Users/harwinder/Desktop/Tableau_Project/final_datasets/seasonal_final_citibike_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the cleaned dataset\n",
    "cleaned_file_path = \"/Users/harwinder/Desktop/Tableau_Project/final_datasets/seasonal_final_citibike_dataset.csv\"\n",
    "merged_dataset.to_csv(cleaned_file_path, index=False)\n",
    "print(f\"Cleaned data saved to: {cleaned_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2a4250-ee0b-4c2a-93a9-f548ae58b4da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
